{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b01db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T-distribution:\n",
    "# The T-distribution, also known as Student's T-distribution, \n",
    "#is a probability distribution used in statistics, particularly in hypothesis testing\n",
    "#and confidence interval estimation when the sample size is small and/or the population standard deviation is unknown.\n",
    "# It is similar to the normal distribution but has heavier tails, meaning \n",
    "#it is more prone to producing values far from its mean.\n",
    "# As the sample size increases, the T-distribution approaches the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef02b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80f19c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give data\n",
    "sample_mean=150\n",
    "sample_std=10\n",
    "sample_size=15\n",
    "confidence_level=0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "371bf369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.581988897471611"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the standard error of the mean\n",
    "sem=sample_std/np.sqrt(sample_size)\n",
    "sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3fc7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the T-critical value\n",
    "t_critical=stats.t.ppf((1+confidence_level)/2,df=sample_size-1)\n",
    "#Calculate the margin of error\n",
    "margin_of_error=t_critical*sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9ec6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.537815415646416"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_of_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b9d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c670a37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_intervel=(sample_mean-margin_of_error,sample_mean+margin_of_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda157cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144.4621845843536, 155.5378154156464)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confidence_intervel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27917acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleMean:: 150\n",
      "T-CriticalValue:: 2.1447866879169273\n",
      "Margin of error:: 5.537815415646416\n",
      "Confidence Intervel:: (144.4621845843536, 155.5378154156464)\n"
     ]
    }
   ],
   "source": [
    "#Display the result\n",
    "print(\"sampleMean::\",sample_mean)\n",
    "print(\"T-CriticalValue::\",t_critical)\n",
    "print(\"Margin of error::\",margin_of_error)\n",
    "print(\"Confidence Intervel::\",confidence_intervel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c117d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing:\n",
    "# Data preprocessing is the process of transforming raw data into a clean and usable format before feeding it into a machine learning model. This step is crucial for improving the model's performance.\n",
    "# Common steps in data preprocessing include:\n",
    "# Data Cleaning: Handling missing values, removing duplicates, and correcting errors in the data.\n",
    "# Data Transformation: Normalizing or standardizing data, encoding categorical variables, and transforming skewed data.\n",
    "# Feature Engineering: Creating new features from existing data to improve model accuracy.\n",
    "# Data Splitting: Dividing the dataset into training, validation, and test sets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
