{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce4753",
   "metadata": {},
   "outputs": [],
   "source": [
    "T-distribution:\n",
    "# The T-distribution, also known as Student's T-distribution, is a probability distribution used in statistics, particularly in hypothesis testing and confidence interval estimation when the sample size is small and/or the population standard deviation is unknown.\n",
    "# It is similar to the normal distribution but has heavier tails, meaning it is more prone to producing values far from its mean.\n",
    "# As the sample size increases, the T-distribution approaches the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b770845f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Mean: 150 grams\n",
      "T-Critical Value: 2.145\n",
      "Margin of Error: 5.538 grams\n",
      "95% Confidence Interval: (144.4621845843536, 155.5378154156464) grams\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given data\n",
    "sample_mean = 150\n",
    "sample_std = 10\n",
    "sample_size = 15\n",
    "confidence_level = 0.95\n",
    "\n",
    "# Calculate the standard error of the mean (SEM)\n",
    "sem = sample_std / np.sqrt(sample_size)\n",
    "\n",
    "# Calculate the t-critical value\n",
    "t_critical = stats.t.ppf((1 + confidence_level) / 2, df=sample_size-1)\n",
    "\n",
    "# Calculate the margin of error\n",
    "margin_of_error = t_critical * sem\n",
    "\n",
    "# Calculate the confidence interval\n",
    "confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Sample Mean: {sample_mean} grams\")\n",
    "print(f\"T-Critical Value: {t_critical:.3f}\")\n",
    "print(f\"Margin of Error: {margin_of_error:.3f} grams\")\n",
    "print(f\"95% Confidence Interval: {confidence_interval} grams\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a7983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing:\n",
    "# Data preprocessing is the process of transforming raw data into a clean and usable format before feeding it into a machine learning model. This step is crucial for improving the model's performance.\n",
    "# Common steps in data preprocessing include:\n",
    "# Data Cleaning: Handling missing values, removing duplicates, and correcting errors in the data.\n",
    "# Data Transformation: Normalizing or standardizing data, encoding categorical variables, and transforming skewed data.\n",
    "# Feature Engineering: Creating new features from existing data to improve model accuracy.\n",
    "# Data Splitting: Dividing the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593049da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given Dataset (Hypothetical):\n",
    "# Columns:\n",
    "# CustomerID: Unique identifier for each customer\n",
    "# Age: Age of the customer\n",
    "# Gender: Gender of the customer (Male, Female)\n",
    "# AnnualIncome: Annual income of the customer\n",
    "# Purchased: Whether the customer made a purchase (0: No, 1: Yes)\n",
    "# Steps in Data Preprocessing:\n",
    "# Handling Missing Values\n",
    "# Encoding Categorical Variables\n",
    "# Feature Scaling\n",
    "# Splitting the Dataset into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a77d77a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azart\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame:\n",
      "   CustomerID  Age  Gender  Salary  Purchased\n",
      "0           1 -1.5       1    -1.5          1\n",
      "1           2 -0.5       0     0.0          0\n",
      "2           3  0.5       0    -0.5          1\n",
      "3           4  0.0       1     0.5          0\n",
      "4           5  1.5       0     1.5          1\n",
      "\n",
      "Training Features (X_train):\n",
      "   Age  Gender  Salary\n",
      "4  1.5       0     1.5\n",
      "2  0.5       0    -0.5\n",
      "0 -1.5       1    -1.5\n",
      "3  0.0       1     0.5\n",
      "\n",
      "Test Features (X_test):\n",
      "   Age  Gender  Salary\n",
      "1 -0.5       0     0.0\n",
      "\n",
      "Training Labels (y_train):\n",
      "4    1\n",
      "2    1\n",
      "0    1\n",
      "3    0\n",
      "Name: Purchased, dtype: int32\n",
      "\n",
      "Test Labels (y_test):\n",
      "1    0\n",
      "Name: Purchased, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Load the data into a DataFrame\n",
    "data = {\n",
    "    'CustomerID': [1, 2, 3, 4, 5],\n",
    "    'Age': [25, 30, 35, None, 40],\n",
    "    'Gender': ['Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Salary': [50000, None, 60000, 70000, 80000],\n",
    "    'Purchased': ['Yes', 'No', 'Yes', 'No', 'Yes']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 2: Handling Missing Values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])\n",
    "df['Salary'] = imputer.fit_transform(df[['Salary']])\n",
    "\n",
    "# Step 3: Encoding Categorical Variables\n",
    "label_encoder_gender = LabelEncoder()\n",
    "df['Gender'] = label_encoder_gender.fit_transform(df['Gender'])\n",
    "\n",
    "label_encoder_purchased = LabelEncoder()\n",
    "df['Purchased'] = label_encoder_purchased.fit_transform(df['Purchased'])\n",
    "\n",
    "# Step 4: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "df[['Age', 'Salary']] = scaler.fit_transform(df[['Age', 'Salary']])\n",
    "\n",
    "# Step 5: Splitting the Data into Training and Test Sets\n",
    "X = df[['Age', 'Gender', 'Salary']]  # Features\n",
    "y = df['Purchased']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the processed data and the train/test splits\n",
    "print(\"Processed DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nTraining Features (X_train):\")\n",
    "print(X_train)\n",
    "print(\"\\nTest Features (X_test):\")\n",
    "print(X_test)\n",
    "print(\"\\nTraining Labels (y_train):\")\n",
    "print(y_train)\n",
    "print(\"\\nTest Labels (y_test):\")\n",
    "print(y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
